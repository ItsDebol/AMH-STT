{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# TRAINING LSTM ASR MODEL"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "import tensorflow as tf\r\n",
    "import scipy.io.wavfile as wav\r\n",
    "import glob\r\n",
    "import numpy as np\r\n",
    "import matplotlib.pyplot as plt\r\n",
    "\r\n",
    "import json\r\n",
    "from python_speech_features import mfcc, logfbank\r\n",
    "import mlflow\r\n",
    "from tensorflow.keras.layers import Conv1D, BatchNormalization, Dense, Activation, Bidirectional, TimeDistributed, Masking, Input, GRU, SimpleRNN\r\n",
    "from tensorflow.keras.models import Model\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "# Constants\r\n",
    "SPACE_TOKEN = '<space>'\r\n",
    "SPACE_INDEX = 0\r\n",
    "FEAT_MASK_VALUE = 1e+10\r\n",
    "\r\n",
    "# Some configs\r\n",
    "num_features = 13\r\n",
    "num_classes = 222 + 1  # 285(including space) + blank label = 286\r\n",
    "\r\n",
    "# Hyper-parameters\r\n",
    "num_epochs = 300\r\n",
    "batch_size = 500\r\n",
    "initial_learning_rate = 0.0005\r\n",
    "momentum = 0.9\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "# Loading the data\r\n",
    "file_path = glob.glob('../data/train/clean_wav/*.wav')\r\n",
    "\r\n",
    "audio_list = []\r\n",
    "fs_list = []\r\n",
    "min_duration = 2\r\n",
    "max_duration = 6\r\n",
    "new_file_path = []\r\n",
    "\r\n",
    "for file_name in file_path:\r\n",
    "    fs, audio = wav.read(file_name)\r\n",
    "    audio_size = audio.size\r\n",
    "    duration = audio_size / fs\r\n",
    "    if(duration >= min_duration and duration <= max_duration):\r\n",
    "        new_file_path.append(file_name)\r\n",
    "        audio_list.append(audio)\r\n",
    "        fs_list.append(fs)\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "# Create a dataset composed of data with variable lengths\r\n",
    "inputs_list = []\r\n",
    "input_type = 'mfcc'\r\n",
    "for index in range(len(audio_list)):\r\n",
    "    if(input_type == 'mfcc'):\r\n",
    "        input_val = mfcc(audio_list[index],\r\n",
    "                         samplerate=fs_list[index], numcep=13)\r\n",
    "        input_val = (input_val - np.mean(input_val)) / np.std(input_val)\r\n",
    "        inputs_list.append(input_val)\r\n",
    "    else:\r\n",
    "        num_features = 161\r\n",
    "        input_val = logfbank(\r\n",
    "            audio_list[index], samplerate=fs_list[index], nfilt=161)\r\n",
    "        input_val = (input_val - np.mean(input_val)) / np.std(input_val)\r\n",
    "        inputs_list.append(input_val)\r\n",
    "\r\n",
    "\r\n",
    "# Transform in 3D Array\r\n",
    "train_inputs = tf.ragged.constant([i for i in inputs_list], dtype=np.float32)\r\n",
    "train_seq_len = tf.cast(train_inputs.row_lengths(), tf.int32)\r\n",
    "train_inputs = train_inputs.to_tensor(default_value=FEAT_MASK_VALUE)\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "with open('../data/train_labels.json', 'r', encoding='UTF-8') as label_file:\r\n",
    "    labels = json.load(label_file)\r\n",
    "with open('../data/alphabets_data.json', 'r', encoding='UTF-8') as alphabets_file:\r\n",
    "    alphabets = json.load(alphabets_file)\r\n",
    "\r\n",
    "#update number of labels\r\n",
    "num_classes = alphabets['alphabet_size'] + 1\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "# Reading Targets\r\n",
    "original_list = []\r\n",
    "targets_list = []\r\n",
    "\r\n",
    "for path in new_file_path:\r\n",
    "    file_name = path[:-4].split('wav')[1][1:].split('#')[0]\r\n",
    "    # Read Label\r\n",
    "    label = labels[file_name]\r\n",
    "    original = \" \".join(label.strip().split(' '))\r\n",
    "    original_list.append(original)\r\n",
    "    # print(original)\r\n",
    "    target = original.replace(' ', '  ')\r\n",
    "    # print('step-1. ',target)\r\n",
    "    target = target.split(' ')\r\n",
    "    # print('step-2. ', target)\r\n",
    "    # Adding blank label\r\n",
    "    target = np.hstack([SPACE_TOKEN if x == '' else list(x) for x in target])\r\n",
    "    # print('step-3. ', target)\r\n",
    "    # Transform char into index\r\n",
    "    target = np.asarray([alphabets['char_to_num'][x] for x in target])\r\n",
    "    # print('step-4. ', target)\r\n",
    "    targets_list.append(target)\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "# Creating sparse representation to feed the placeholder\r\n",
    "train_targets = tf.ragged.constant([i for i in targets_list], dtype=np.int32)\r\n",
    "train_targets_len = tf.cast(train_targets.row_lengths(), tf.int32)\r\n",
    "train_targets = train_targets.to_sparse()\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "size, row = train_targets.shape\r\n",
    "train_size = int(size * 0.8)\r\n",
    "val_size = size - train_size\r\n",
    "print(train_size, val_size)\r\n",
    "print(row)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "4065 1017\n",
      "70\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "# Split Training and Validation sets\r\n",
    "\r\n",
    "train_inputs_final, val_inputs_final = train_inputs[:train_size], train_inputs[train_size:]\r\n",
    "train_seq_len_final, val_seq_len_final = train_seq_len[:train_size], train_seq_len[train_size:]\r\n",
    "train_targets_final, val_targets_final = tf.sparse.slice(train_targets, start=[0, 0], size=[\r\n",
    "                                                         train_size, row]), tf.sparse.slice(train_targets, start=[train_size, 0], size=[train_size, row])\r\n",
    "train_targets_len_final, val_targets_len_final = train_targets_len[\r\n",
    "    :train_size], train_targets_len[train_size:]\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "source": [
    "print(train_inputs_final.shape, val_inputs_final.shape)\r\n",
    "print(train_seq_len_final.shape, val_seq_len_final.shape)\r\n",
    "print(train_targets_final.shape, val_targets_final.shape)\r\n",
    "print(train_targets_len_final.shape, val_targets_len_final.shape)\r\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(4065, 591, 13) (1017, 591, 13)\n",
      "(4065,) (1017,)\n",
      "(4065, 70) (1017, 70)\n",
      "(4065,) (1017,)\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "source": [
    "class CTCLossLayer(tf.keras.layers.Layer):\r\n",
    "    def call(self, inputs):\r\n",
    "        labels = inputs[0]\r\n",
    "        logits = inputs[1]\r\n",
    "        label_len = inputs[2]\r\n",
    "        logit_len = inputs[3]\r\n",
    "\r\n",
    "        logits_trans = tf.transpose(logits, (1, 0, 2))\r\n",
    "        label_len = tf.reshape(label_len, (-1,))\r\n",
    "        logit_len = tf.reshape(logit_len, (-1,))\r\n",
    "        loss = tf.reduce_mean(tf.nn.ctc_loss(\r\n",
    "            labels, logits_trans, label_len, logit_len, blank_index=-1))\r\n",
    "        # define loss here instead of in compile\r\n",
    "        self.add_loss(loss)\r\n",
    "\r\n",
    "        # Decode\r\n",
    "        decoded, _ = tf.nn.ctc_greedy_decoder(logits_trans, logit_len)\r\n",
    "\r\n",
    "        # Inaccuracy: label error rate\r\n",
    "        ler = tf.reduce_mean(tf.edit_distance(\r\n",
    "            tf.cast(decoded[0], tf.int32), labels))\r\n",
    "        self.add_metric(ler, name='ler', aggregation='mean')\r\n",
    "\r\n",
    "        return logits\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "source": [
    "# Definning Input Parameters\r\n",
    "input_feature = tf.keras.layers.Input(\r\n",
    "    (None, num_features), name='input_feature')\r\n",
    "input_label = tf.keras.layers.Input(\r\n",
    "    (None,), dtype=tf.int32, sparse=True, name='input_label')\r\n",
    "input_feature_len = tf.keras.layers.Input(\r\n",
    "    (1,), dtype=tf.int32, name='input_feature_len')\r\n",
    "input_label_len = tf.keras.layers.Input(\r\n",
    "    (1,), dtype=tf.int32, name='input_label_len')\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "source": [
    "input_masking = tf.keras.layers.Masking(FEAT_MASK_VALUE)(input_feature)\r\n",
    "x = tf.keras.layers.LSTM(100, return_sequences=True)(input_masking)\r\n",
    "x_1 = tf.keras.layers.BatchNormalization()(x)\r\n",
    "x_2 = tf.keras.layers.LSTM(100, return_sequences=True)(x_1)\r\n",
    "x_3 = tf.keras.layers.BatchNormalization()(x_2)\r\n",
    "x_4 = tf.keras.layers.LSTM(100, return_sequences=True)(x_3)\r\n",
    "x_5 = tf.keras.layers.BatchNormalization()(x_4)\r\n",
    "x_6 = tf.keras.layers.LSTM(100, return_sequences=True)(x_5)\r\n",
    "x_7 = tf.keras.layers.BatchNormalization()(x_6)\r\n",
    "x_8 = tf.keras.layers.LSTM(100, return_sequences=True)(x_7)\r\n",
    "# x = tf.keras.layers.BatchNormalization()(x)\r\n",
    "# layer_rnn = tf.keras.layers.LSTM(10, return_sequences=True)(layer_bn)\r\n",
    "# x = tf.keras.layers.Dropout(0.2, seed=42)(x)\r\n",
    "layer_output = tf.keras.layers.TimeDistributed(Dense(num_classes, kernel_initializer=tf.keras.initializers.TruncatedNormal(\r\n",
    "    0.0, 0.1), bias_initializer='zeros', name='logit'))(x_8)\r\n",
    "\r\n",
    "layer_loss = CTCLossLayer()(\r\n",
    "    [input_label, layer_output, input_label_len, input_feature_len])\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "source": [
    "# Create models for training and prediction\r\n",
    "model_train = tf.keras.models.Model(inputs=[input_feature, input_label, input_feature_len, input_label_len],\r\n",
    "                                    outputs=layer_loss)\r\n",
    "print(model_train.summary())\r\n",
    "model_predict = tf.keras.models.Model(\r\n",
    "    inputs=input_feature, outputs=layer_output)\r\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_feature (InputLayer)      [(None, None, 13)]   0                                            \n",
      "__________________________________________________________________________________________________\n",
      "masking (Masking)               (None, None, 13)     0           input_feature[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "lstm (LSTM)                     (None, None, 100)    45600       masking[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization (BatchNorma (None, None, 100)    400         lstm[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "lstm_1 (LSTM)                   (None, None, 100)    80400       batch_normalization[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, None, 100)    400         lstm_1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "lstm_2 (LSTM)                   (None, None, 100)    80400       batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, None, 100)    400         lstm_2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "lstm_3 (LSTM)                   (None, None, 100)    80400       batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, None, 100)    400         lstm_3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "lstm_4 (LSTM)                   (None, None, 100)    80400       batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "input_label (InputLayer)        [(None, None)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed (TimeDistribut (None, None, 223)    22523       lstm_4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "input_label_len (InputLayer)    [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_feature_len (InputLayer)  [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "ctc_loss_layer (CTCLossLayer)   (None, None, 223)    0           input_label[0][0]                \n",
      "                                                                 time_distributed[0][0]           \n",
      "                                                                 input_label_len[0][0]            \n",
      "                                                                 input_feature_len[0][0]          \n",
      "==================================================================================================\n",
      "Total params: 391,323\n",
      "Trainable params: 390,523\n",
      "Non-trainable params: 800\n",
      "__________________________________________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "source": [
    "# Compile Training Model with selected optimizer\r\n",
    "optimizer = tf.keras.optimizers.SGD(initial_learning_rate, momentum)\r\n",
    "model_train.compile(optimizer=optimizer)\r\n",
    "\r\n",
    "checkpointer = tf.keras.callbacks.ModelCheckpoint(filepath='../models/'+\"RNN\"+'.h5',\r\n",
    "                               monitor='val_loss', verbose=1, save_best_only=True, mode='min')\r\n",
    "# ModelCheckpoint(filepath='../models/'+\"RNN\"+'.h5', verbose=0,)\r\n",
    "\r\n",
    "mlflow.set_experiment(\"STACKED LSTM Layers\")\r\n",
    "mlflow.tensorflow.autolog()\r\n",
    "history = model_train.fit(x=[train_inputs_final, train_targets_final, train_seq_len_final, train_targets_len_final], y=None,\r\n",
    "                          validation_data=(\r\n",
    "                              [val_inputs_final, val_targets_final, val_seq_len_final, val_targets_len_final], None),\r\n",
    "                          batch_size=batch_size, epochs=num_epochs)\r\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "2021/08/12 20:55:33 INFO mlflow.utils.autologging_utils: Created MLflow autologging run with ID '9fd287c6289a463292de6b7c1667ebcc', which will track hyperparameters, performance metrics, model artifacts, and lineage information for the current tensorflow workflow\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1/300\n"
     ]
    },
    {
     "output_type": "error",
     "ename": "CancelledError",
     "evalue": " [_Derived_]RecvAsync is cancelled.\n\t [[{{node model/ctc_loss_layer/Rank/_42}}]]\n\t [[model/ctc_loss_layer/transpose/_30]] [Op:__inference_train_function_34765]\n\nFunction call stack:\ntrain_function\n",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mCancelledError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-15-8e0d0c044948>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[0mmlflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_experiment\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"STACKED LSTM Layers\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[0mmlflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mautolog\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m history = model_train.fit(x=[train_inputs_final, train_targets_final, train_seq_len_final, train_targets_len_final], y=None,\n\u001b[0m\u001b[0;32m     12\u001b[0m                           validation_data=(\n\u001b[0;32m     13\u001b[0m                               [val_inputs_final, val_targets_final, val_seq_len_final, val_targets_len_final], None),\n",
      "\u001b[1;32mC:\\Python38\\lib\\site-packages\\mlflow\\utils\\autologging_utils\\safety.py\u001b[0m in \u001b[0;36msafe_patch_function\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    488\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    489\u001b[0m                     \u001b[1;32mif\u001b[0m \u001b[0mpatch_is_class\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 490\u001b[1;33m                         \u001b[0mpatch_function\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcall\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcall_original\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    491\u001b[0m                     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    492\u001b[0m                         \u001b[0mpatch_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcall_original\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Python38\\lib\\site-packages\\mlflow\\utils\\autologging_utils\\safety.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(cls, original, *args, **kwargs)\u001b[0m\n\u001b[0;32m    154\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0mclassmethod\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    155\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mcall\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moriginal\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 156\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mcls\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moriginal\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    157\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    158\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moriginal\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Python38\\lib\\site-packages\\mlflow\\utils\\autologging_utils\\safety.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, original, *args, **kwargs)\u001b[0m\n\u001b[0;32m    165\u001b[0m                 \u001b[1;31m# Regardless of what happens during the `_on_exception` callback, reraise\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    166\u001b[0m                 \u001b[1;31m# the original implementation exception once the callback completes\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 167\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    168\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    169\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Python38\\lib\\site-packages\\mlflow\\utils\\autologging_utils\\safety.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, original, *args, **kwargs)\u001b[0m\n\u001b[0;32m    158\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moriginal\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    159\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 160\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_patch_implementation\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moriginal\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    161\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mException\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    162\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Python38\\lib\\site-packages\\mlflow\\utils\\autologging_utils\\safety.py\u001b[0m in \u001b[0;36m_patch_implementation\u001b[1;34m(self, original, *args, **kwargs)\u001b[0m\n\u001b[0;32m    216\u001b[0m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmanaged_run\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtry_mlflow_log\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcreate_managed_run\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    217\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 218\u001b[1;33m                 result = super(PatchWithManagedRun, self)._patch_implementation(\n\u001b[0m\u001b[0;32m    219\u001b[0m                     \u001b[0moriginal\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    220\u001b[0m                 )\n",
      "\u001b[1;32mC:\\Python38\\lib\\site-packages\\mlflow\\tensorflow.py\u001b[0m in \u001b[0;36m_patch_implementation\u001b[1;34m(self, original, inst, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1095\u001b[0m                 \u001b[0m_log_early_stop_callback_params\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mearly_stop_callback\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1096\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1097\u001b[1;33m                 \u001b[0mhistory\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0moriginal\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minst\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1098\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1099\u001b[0m                 \u001b[0mepochs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>=\u001b[0m \u001b[1;36m4\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"epochs\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Python38\\lib\\site-packages\\mlflow\\utils\\autologging_utils\\safety.py\u001b[0m in \u001b[0;36mcall_original\u001b[1;34m(*og_args, **og_kwargs)\u001b[0m\n\u001b[0;32m    446\u001b[0m                                 \u001b[0mdisable_warnings\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreroute_warnings\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    447\u001b[0m                             ):\n\u001b[1;32m--> 448\u001b[1;33m                                 \u001b[0moriginal_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0moriginal\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mog_args\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mog_kwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    449\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    450\u001b[0m                             try_log_autologging_event(\n",
      "\u001b[1;32mC:\\Python38\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1181\u001b[0m                 _r=1):\n\u001b[0;32m   1182\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1183\u001b[1;33m               \u001b[0mtmp_logs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1184\u001b[0m               \u001b[1;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1185\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Python38\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    887\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    888\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 889\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    890\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    891\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Python38\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    948\u001b[0m         \u001b[1;31m# Lifting succeeded, so variables are initialized and we can run the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    949\u001b[0m         \u001b[1;31m# stateless function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 950\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    951\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    952\u001b[0m       \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfiltered_flat_args\u001b[0m \u001b[1;33m=\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Python38\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   3021\u001b[0m       (graph_function,\n\u001b[0;32m   3022\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m-> 3023\u001b[1;33m     return graph_function._call_flat(\n\u001b[0m\u001b[0;32m   3024\u001b[0m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0;32m   3025\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Python38\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1958\u001b[0m         and executing_eagerly):\n\u001b[0;32m   1959\u001b[0m       \u001b[1;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1960\u001b[1;33m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[0;32m   1961\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0;32m   1962\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001b[1;32mC:\\Python38\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    589\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    590\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 591\u001b[1;33m           outputs = execute.execute(\n\u001b[0m\u001b[0;32m    592\u001b[0m               \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    593\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Python38\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     57\u001b[0m   \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 59\u001b[1;33m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[0;32m     60\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[0;32m     61\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mCancelledError\u001b[0m:  [_Derived_]RecvAsync is cancelled.\n\t [[{{node model/ctc_loss_layer/Rank/_42}}]]\n\t [[model/ctc_loss_layer/transpose/_30]] [Op:__inference_train_function_34765]\n\nFunction call stack:\ntrain_function\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "print(history.history.keys())\r\n",
    "# summarize history for accuracy\r\n",
    "plt.plot(history.history['loss'])\r\n",
    "plt.plot(history.history['val_loss'])\r\n",
    "plt.title('model Loss')\r\n",
    "plt.ylabel('Loss')\r\n",
    "plt.xlabel('epoch')\r\n",
    "plt.legend(['Training Loss', 'Validation Loss'], loc='upper left')\r\n",
    "plt.show()\r\n"
   ],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.8.4",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.4 64-bit"
  },
  "interpreter": {
   "hash": "2db524e06e9f5f4ffedc911c917cb75e12dbc923643829bf417064a77eb14d37"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}